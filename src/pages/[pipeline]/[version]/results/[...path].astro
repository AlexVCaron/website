---
import PipelinePageLayout from '@layouts/PipelinePageLayout.astro';
import pipelines_json from '@public/pipelines.json';
import { parseStringPromise } from 'xml2js';

// import AWSBrowser from '@components/pipeline/AWSBrowser.svelte';

const { pipeline, version, path } = Astro.params;
const meta = pipelines_json.remote_workflows.find((p) => p.name === pipeline);
const versions = meta.releases.map((release) => release.tag_name);
const md_files = meta.releases
    .find((release) => release.tag_name === version)
    .doc_files.map((file) => file.replace('docs/', '').replace('.md', ''));
const releaseSHA = meta.releases.find((release) => release.tag_name === version).sha;

let directories = [];
let sortedDirectories = [];
let files = [];
let bucketContents = [];

const bucketName = 'nf-core-awsmegatests';
const prefix = `${pipeline}/results-${releaseSHA}`;

try {
    let isTruncated = true;
    let marker = '';
    let allKeys = [];

    while (isTruncated) {
        const response = await fetch(`https://${bucketName}.s3.amazonaws.com/?prefix=${prefix}&marker=${marker}`);
        const data = await response.text();

        const parsedData = await parseStringPromise(data);
        const contents = parsedData?.ListBucketResult?.Contents || [];
        const keys = contents.map((item) => item.Key[0]);
        allKeys = allKeys.concat(keys);
        isTruncated = parsedData?.ListBucketResult?.IsTruncated[0] === 'true';
        marker = keys[keys.length - 1] || '';
    }

    bucketContents = allKeys;
    directories = bucketContents.filter((item) => item.endsWith('/'));
    sortedDirectories = directories
        .map((item) => {
            return {
                name: item.replace(prefix, ''),
                path: item,
                depth: item.replace(prefix, '').split('/').length,
            };
        })
        .sort((a, b) => a.depth - b.depth);

    // check if element has object of depth 3 and if it does not, create and add the parent object
    const depth3 = sortedDirectories.find((item) => item.depth === 3);
    if (!depth3) {
        // create parent objects based on the parent directory of sortedDirectories
        const parents = sortedDirectories
            .filter((item) => item.depth === 4)
            .map((item) => {
                const parent = item.name.split('/').slice(0, -2).join('/') + '/';

                return {
                    name: parent,
                    path: prefix + parent,
                    depth: parent.split('/').length,
                };
            });
        // remove duplicated entries in parents
        const uniqueParents = [...new Map(parents.map((item) => [item.name, item])).values()];
        // add parents to sortedDirectories
        sortedDirectories = uniqueParents.concat(sortedDirectories);
    }

    files = bucketContents
        .filter((item) => !item.endsWith('/'))
        .map((item) => {
            console.log('item', item);
            return {
                name: item.replace(prefix, ''),
                path: item,
                depth: item.replace(prefix, '').split('/').length,
            };
        })
        .sort((a, b) => a.depth - b.depth);
} catch (error) {
    console.error('Error:', error);
}
if (!path) {
    console.log('redirecting');
    return Astro.redirect('results/' + prefix);
}
console.log('path', path, path.split('/'));
const description = meta?.description;
const depth = path.endsWith('/') ? path.split('/').length - 1 : path.split('/').length;

console.log(sortedDirectories.filter((item) => item.depth === depth + 1));

export const prerender = false;
---

<PipelinePageLayout
    pipeline={pipeline}
    subtitle={description}
    version={version}
    versions={versions}
    tabItems={md_files}
>
    <ul>
        releaesSHA: {releaseSHA}
        {
            sortedDirectories &&
                sortedDirectories
                    .filter((item) => item.depth === depth + 1)
                    .map((item) => (
                        <li>
                            <a href={`https://${bucketName}.s3.amazonaws.com/${item}`}>{item.name}</a>
                        </li>
                    ))
        }
        {
            files &&
                files
                    .filter((item) => item.depth === depth)
                    .map((item) => (
                        <li>
                            <a href={`https://${bucketName}.s3.amazonaws.com/${item}`}>{item.name}</a>
                        </li>
                    ))
        }
    </ul>
</PipelinePageLayout>
