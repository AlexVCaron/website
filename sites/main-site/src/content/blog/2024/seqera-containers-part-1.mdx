---
title: 'Migration from Biocontainers to Seqera Containers: Part 1'
subtitle: What Seqera Containers is and why we want to move to it.
pubDate: 2024-09-12T09:00:00+01:00
headerImage: https://images.unsplash.com/photo-1517061391662-b09454c10462
headerImageAlt: Photo by Barth Bailey on Unsplash
authors:
    - 'ewels'
    - 'edmundmiller'
label:
    - 'modules'
    - 'wave'
    - 'seqera containers'
embedHeaderImage: false
---

import butwhy from '@assets/images/blog/seqera-containers-part-1/simone-secci-49uySSA678U-unsplash.jpg';
import mulled from '@assets/images/blog/seqera-containers-part-1/hannah-pemberton-bXi4eg4jyuU-unsplash.jpg';
import chillies from '@assets/images/blog/seqera-containers-part-1/anne-nygard-3tPkwnNRRkI-unsplash.jpg';
import leaves from '@assets/images/blog/seqera-containers-part-1/providence-doucet-mE5MBZX5sko-unsplash.jpg';

import { Image } from 'astro:assets';

In spring 2024, Seqera and AWS launched a new free community resource: Seqera Containers (see [summit talk](https://summit.nextflow.io/2024/boston/agenda/05-23--whats-new-in-the-nextflow/), [blog post](https://seqera.io/blog/introducing-seqera-pipelines-containers/), [podcast](https://nextflow.io/podcast/2024/ep38_seqera_pipelines_containers.html)). Seqera Containers allows anyone to request a container image based on Conda or PyPI packages. The image is built on demand and then saved so that subsequent requests return the exact same container image files.

We intend to adopt Seqera Containers for all nf-core modules and pipelines. In this blog post we'll cover the why, how and what this means for you.

:::tip{title="Key points"}

-   Developers will _only_ need to edit the conda `environment.yml` (no process `container`)
-   Container images will be built by Wave and stored in Seqera Containers
-   Build logs and source files will be shown on the nf-core website module pages
-   Conda lock-files will be used for Conda users and CI tests
-   Software releases will be automatically bumped in modules, using [Renovate](https://renovatebot.com/)
-   There should be almost no change in how end-users run nf-core pipelines

:::

:::info{.fa-clock title="Timeline"}

Before we can start migrating all modules, we need to build:

-   nf-core/tools automation for config file generation, with pipeline template update
-   nf-core/modules automation for fetching images and pinning conda-lock files and `meta.yml` reference

Part 2 of this blog post will cover the technical details of how we plan to build this tooling.

If all goes to plan, we hope to be finished by the end of 2024. This work will be tracked in GitHub issues as usual, starting with [nf-core/modules#5832](https://github.com/nf-core/modules/issues/5832). This issue has already had a substantial amount of discussion, much of which has informed this blog post. We want to hear your feedback! So if you have any questions or ideas, let us know on Github or in Slack.

Note that Seqera Containers _can_ already be used in nf-core/modules, with the old syntax of using a `container` declaration.

:::

## Background

Software containers are a fundamental part of modern bioinformatics workflows. Nextflow supports multiple container platforms, but the two most commonly used are Docker and Singularity. The concept is simple: all of the software requirements for a specific Nextflow process are wrapped up into a container image and referenced within the pipeline code. The process tasks run in isolation of the host environment and the end user doesn't need to worry about installing software dependencies for the pipeline. Best of all, the software builds are locked in time making results highly reproducible over many years.

To ensure maximum compatibility and reproducibility across compute environments, nf-core modules are typically set up with a conda `environment.yml`, listing software package dependencies from [Bioconda](https://bioconda.github.io/) for conda users.
The BioContainers project automatically builds Docker and Singularity images whenever a new tool is released on Bioconda, hosting the images publicly on [quay.io](quay.io) and the Galaxy FTP servers, respectively.
The nf-core module developer finds the matching [BioContainer](https://biocontainers.pro/) image URLs, which they hardcode into the module's `main.nf` script.

The Bioconda and BioContainer projects have been invaluable to the success of nf-core. We're hugely grateful to all contributors for the work that they put in, as well to the Galaxy project for hosting.

## Why change?

<Image class="d-block ms-3 mb-3 float-end rounded w-25 shadow" src={butwhy} alt="Photo by Simone Secci on Unsplash." />

Bioconda and BioContainers have worked very well for nf-core, so why change now? The motivation comes down to a few key reasons:

-   Difficulties with BioContainers
    -   Mulled (multi-package) images
    -   Reliability of hosting
    -   BioContainers API
-   New features with Seqera Containers
    -   Conda lock files
    -   Simplified developer workflow
    -   Better transparency

But before we discuss those in detail, it's important to understand…

### How is Seqera Containers different?

The Seqera Containers service has a lot in common with BioContainers. Both generate Docker and Singularity images from Bioconda. The main difference is _when_ those builds happen.

Seqera Containers is built on top of [Wave](https://seqera.io/wave/) - an open-source tool by Seqera for **on-demand** generation of containers. When a new tool or version is requested, Wave builds a container using Conda and returns it. In contrast, BioContainers runs a build when a new package is created on Bioconda. Building on-demand gives greater flexibility and scalability, especially for multi-tool containers.

Whilst Seqera Containers are built using Wave, we're not suggesting that nf-core pipeline users should interact with Wave directly. We simply want to replace the mechanism for supplying pre-existing container images in pipelines.

<div class="small">
<table class="table table-sm table-hover">
    <thead>
        <tr>
            <td></td>
            <th>BioContainers</th>
            <th>Wave</th>
            <th>Seqera&nbsp;Containers</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Support Bioconda packages</td>
            <td>✅</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Support all conda channels</td>
            <td>❌</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Support PyPI (pip) packages</td>
            <td>❌</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Docker + Singularity support</td>
            <td>✅</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Linux aarch64 and arm64</td>
            <td>⏳ In progress</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Multi-package containers</td>
            <td>✅ Mulled</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Conda lock files generated</td>
            <td>❌</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Container build logs</td>
            <td>❌ CI logs short lived</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Docker container security scans</td>
            <td>✅ quay.io</td>
            <td>✅ Trivy</td>
            <td>✅ Trivy</td>
        </tr>
        <tr>
            <td>SBOM manifests (software bill of materials)</td>
            <td>❌</td>
            <td>✅</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Long storage duration</td>
            <td>✅ *</td>
            <td>❌ 72 hours cache</td>
            <td>✅ *</td>
        </tr>
        <tr>
            <td>Pull delay for conda packages</td>
            <td>✅ instant</td>
            <td>❌ ~2-3 minutes for build on first request</td>
            <td>✅ instant</td>
        </tr>
        <tr>
            <td>Stable image URIs</td>
            <td>✅</td>
            <td>❌ Single-run</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Software required for end user</td>
            <td>Docker / Singularity</td>
            <td>Wave CLI / Nextflow, Docker / Singularity</td>
            <td>Docker / Singularity</td>
        </tr>
        <tr>
            <td>Offline support with downloaded images</td>
            <td>✅</td>
            <td>❌</td>
            <td>✅</td>
        </tr>
        <tr>
            <td>Guaranteed identical conda builds in future image pulls</td>
            <td>✅</td>
            <td>❌</td>
            <td>✅</td>
        </tr>
    </tbody>
</table>

> \* Forever is a long time, and we're not fortune tellers. To help the community trust the program, Seqera is committing to keeping images for a minimum of 5 years after they're built. BioContainers has no public policy, images will presumably remain until quay.io / Galaxy remove support.

</div>

### Mulled (multi-package) images

<Image
    class="d-block ms-3 mb-3 float-end rounded w-25 shadow"
    src={mulled}
    alt="Photo by Hannah Pemberton on Unsplash."
/>

BioContainers is primarily set up to have a 1:1 relationship with Bioconda. This is great for bioinformatics tools: When a package is published, it gets an image. This works well until you need to use more than one tool in a single process, and particularly when the tools are from elsewhere in the conda ecosystem. For example, many bioinformatics tools leverage [samtools](https://www.htslib.org/) to convert file formats or sort reads on the fly. Others may pipe output to compression tools like [pigz](https://zlib.net/pigz/). To resolve this, BioContainers has the concept of “mulled” images (as in [mulled wine](https://en.wikipedia.org/wiki/Mulled_wine)).

Unfortunately, generating mulled containers is not trivial. Luke Pembleton, Nextflow Ambassador, has a great blog post summarising the dark art of [Finding the right mulled biocontainer](https://lpembleton.rbind.io/posts/mulled-biocontainers/). Galaxy also has [documentation on the topic](https://docs.galaxyproject.org/en/master/admin/container_resolvers.html). In short, to request an image you edit a [CSV file of hashes](https://github.com/BioContainers/multi-package-containers/blob/master/combinations/hash.tsv) in a GitHub repo, scroll all the way to the bottom, and add a line with your requested conda packages. Once edited, the images are built on CI. It used to be that you had to hunt through the GitHub action log to find the URI for your new container. However, [Moriz E. Beber](https://github.com/Midnighter) from the nf-core community has created a webpage to [generate the name of the mulled container](https://midnighter.github.io/mulled) which gently guides you through the process of finding the name of your container and how to update a container if you want to bump the software versions. Once the image is built and you know its address, the final step is to go to nf-core/modules and create a pull-request with the updated containers and bump the versions in the conda `environment.yml`.

This system works and, despite its complexity, is now a familiar process to many nf-core developers. However it does present some problems. It's a highly manual process to update software versions and update the container declarations – just fetching the software for a module often ends up taking longer than writing the entire module. There are also significant delays in waiting for the images to become available. All in all, it can be a frustrating experience and we see this in the volume of Slack messages asking for help. It seems likely that this puts some people off from contributing to nf-core.

Migrating nf-core to use Seqera Containers will make provisioning multi-package containers trivial. The module developer will only need to edit the module `environment.yml` file and everything else will be fully automated and available almost immediately. Packages can be used minutes after their release on Bioconda and we will even have automation in place to bump the Conda + Seqera Containers packages when a tool is updated.

### BioContainers API

To simplify adding single-package BioContainer images to nf-core modules, we have developed the nf-core/tools package to query the BioContainer API for a given tool version and fetch the image URIs. This process is repeated during linting of nf-core modules and pipelines, to ensure that there is not an accidental mismatch between Conda and Docker / Singularity software versions. Unfortunately, the BioContainer API has had a history of being slow and unreliable, with a lot of down time (204 error message anyone?). This has the knock-on effect of causing many CI tests to fail, which is frustrating and delays the process of pull-request merges.

By migrating to Seqera Containers we will have similar automation when linting modules, but it will use the Seqera Wave API instead. This has been built to scale to very high volumes and has an extensive and robust back-end with a high degree of monitoring. As a reminder: the Wave API will _not_ be used when people run nf-core pipelines, this is only developers running linting and GitHub Actions automation during development.

### Reliability of hosting

BioContainer Docker images are hosted publicly on [quay.io](http://quay.io). This service is provided free of charge, however in recent years we have had some reliability issues. This becomes more noticeable as the community grows and the number of users trying to pull images increases. Because quay.io is a huge service for whom we are only a tiny player, we have no recourse when this happens and have to just wait until it becomes available again.

Seqera serves nf-core as its primary community: as such it should be in a position to respond immediately to any problems or needs. All Seqera Container images (Docker and Singularity) are hosted on custom infrastructure built by Seqera with hosting provided by AWS, so the whole stack is within reach.

## Potential concerns

<Image class="d-block ms-3 mb-3 float-end rounded w-25 shadow" src={chillies} alt="Photo by Anne Nygård on Unsplash." />

### Will these be reproducible?

Because the images are hosted on long-term infrastructure and their URLs are hardcoded into pipeline configuration, they should be highly reproducible. Even if new builds of the same software are created in the future using Wave (for example due to an update in the base infrastructure used by Wave) then the old images are still pinned by the pipeline and will continue to be used, much like the BioContainer URIs used currently.

Because the container URIs are stored in the module-level `meta.yml` file, any pipelines using the same shared nf-core/module will also be using the exact same container images.

We will further improve reproducibility at the conda level by adopting the use of conda lock-files. These pin the exact dependency stack used by the build, not just the top level primary tool being requested. This effectively removes the need for conda to solve the build and also ships md5 hashes for every package. This will greatly improve the reproducibility of the software environments for conda users, as well as improving reliability of Conda CI tests.

### How can I trust the container image?

Reproducibility is one thing, but it's also important that the images we use can be trusted and are secure. Users and developers must be able to verify that the contents of the container match the `environment.yml` for the module.

The first point of trust is the `community.wave.seqera.io` base URI. This is only used for Seqera Containers and only `wave.seqera.io` is able to push images. It is also more locked-down than regular Wave, only allowing Conda builds and not custom Dockerfiles or augmented images.

Second, the image URI includes a tag that has a hash of the input files used to request the image. Consider the image for MultiQC v1.24.1:

The final `789bc3917c8666da` part is the hash - from this we can infer the Wave Build ID and retrieve the build details: [https://wave.seqera.io/view/builds/789bc3917c8666da_1](https://wave.seqera.io/view/builds/789bc3917c8666da_1)

We will update the nf-core website to query this build log for every container in every nf-core module. The response will allow us to embed a lot of audit data for the build:

-   Build time, architecture and platform (Docker / Singularity)
-   `Dockerfile` / Singularity recipe and Conda `environment.yml`
-   Full build logs
-   Conda lock files with full package URLs and md5sums for entire dependency resolution
-   For Docker images: Trivy security scan and software bill of materials (SBOM)

The conda lock files also allow enhanced reproducibility for Conda users and more stable CI tests - we'll come back to these in a future blog post / bytesize.

Finally, the image creation will happen automatically on GitHub Actions when an `environment.yml` file is edited. This means that the entire flow from conda file through to final containers will be entirely transparent, as the request to Wave itself and its response will be available in the GitHub Actions logs.

### What if we change our minds?

Using Seqera Containers does not mean that nf-core will be locked into using Seqera tooling. The suggested implementation has two components:

1. Automated on-demand generation of container images using Wave
2. Long term hosting images on Seqera Containers

The tooling for image generation is [open-source](https://github.com/seqeralabs/wave). Seqera is hosting this API and build service for us for free, but there's nothing to stop us from hosting the same API ourselves in the future if we wish. As such, there is no lock-in on this API or any of the tooling which we will write around it.

Long term hosting is more fixed, but again Wave is designed to work with _any_ container registry. So if we want to change in the future we simply flip a configuration value and the generated images will be stored (“frozen”) at an alternative registry of our choosing. Old pipelines would need to have their configuration overwritten to use a different base registry, but this is a relatively simple step.

In other words, this is exactly the same situation that we have currently with BioContainers and quay.io / Galaxy hosting. The nf-core community will remain free to pick and choose hosting solutions as needed.

### Edge cases

Not all tools can use Biocontainers, and we're aware of some special-case packages that have only bespoke Docker images. These will continue to work as they do today.

### Can I still use my custom registry?

Yes - switching out the container registry base will still work in exactly the same way as it does today. You'll also be able to use Wave with these images in Seqera Containers if you wish - for example to mirror to your custom container registry, or augment with additional tools such as Seqera Fusion.

## What this means for you

### Users

If you're using nf-core pipelines but not developing them, then nothing should really change! All nf-core modules and pipelines should start supporting linux/arm64 CPU architectures, such as AWS Graviton / Raspberry Pis(!). Conda users should benefit from faster environment resolution and more stable software thanks to use of the lock files. You may see a slight improvement in stability as we phase out our usage of quay.io, but this is minor and mostly only affects people running at high scale.

### Developers

If you're a maintainer of a pipeline that uses nf-core/modules, this means that your life is about to get easier! Never again will you need to try to figure out how to make a mulled image, or wonder when your Singularity image build will be available. New software releases can be used with modules within minutes of release and most updates should happen automatically - freeing up maintainers from having to deal with routine package updates and reviews.

In part-two of this blog post we dive into the details of how we intend to build this tooling infrastructure in nf-core, so please check that out if you're interested.

## In conclusion

We hope that the nf-core community is excited about these proposals, if you have any questions or concerns then please do let us know in the nf-core Slack ❤️

<Image
    class="d-block ms-3 mb-3 float-end rounded w-100 shadow"
    src={leaves}
    alt="Photo by Providence Doucet on Unsplash."
/>
